Device: cuda
Data directory: ./data
Seed: 20244078
Data name: korea-all
./data/corr-korea-simple.png
./data/corr-korea-basic.png
./data/preprocessed/korea-complex-test.csv
./data/preprocessed/korea-basic-test.csv
./data/preprocessed/korea-all.csv
./data/preprocessed/korea-simple-train.csv
./data/preprocessed/korea-medium-train.csv
./data/preprocessed/korea-basic-train.csv
./data/preprocessed/.DS_Store
./data/preprocessed/korea-complex-train.csv
./data/preprocessed/korea-all-test.csv
./data/preprocessed/korea-complex.csv
./data/preprocessed/korea-simple.csv
./data/preprocessed/korea-basic.csv
./data/preprocessed/korea-simple-test.csv
./data/preprocessed/korea-all-train.csv
./data/preprocessed/korea-medium.csv
./data/preprocessed/korea-medium-test.csv
Number of columns with NaN: 0
Correlation matrix save path: ./data/corr-korea-all.png

A1                  0.614000
A2_1                0.539537
A2_2                0.520460
A2_3                0.480385
A3_1                0.537739
                      ...   
grdpno              0.014356
jobopen             0.012599
land                0.021315
trainee             0.022463
happiness_ladder    1.000000
Name: happiness_ladder, Length: 309, dtype: float64

==========

Batch size: 32
Number of input features: 309
Lucky number: 42
Epochs: 200
Adam betas: 0.9, 0.999
Criterion: MSE loss


Training for korea-all dataset with features=[309, 42, 84, 168, 336, 672, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.79	Test SSE:   26.17
Epoch: 40	Train Loss:  0.73	Test SSE:   26.91
Epoch: 60	Train Loss:  0.68	Test SSE:   26.35
Epoch: 80	Train Loss:  0.65	Test SSE:   26.05
Epoch: 100	Train Loss:  0.61	Test SSE:   27.10
Epoch: 120	Train Loss:  0.59	Test SSE:   26.35
Epoch: 140	Train Loss:  0.57	Test SSE:   26.18
Epoch: 160	Train Loss:  0.55	Test SSE:   27.26
Epoch: 180	Train Loss:  0.53	Test SSE:   28.53
Epoch: 200	Train Loss:  0.52	Test SSE:   27.80

Training for korea-all dataset with features=[309, 42, 84, 168, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.77	Test SSE:   27.36
Epoch: 40	Train Loss:  0.72	Test SSE:   25.97
Epoch: 60	Train Loss:  0.69	Test SSE:   25.91
Epoch: 80	Train Loss:  0.66	Test SSE:   27.94
Epoch: 100	Train Loss:  0.63	Test SSE:   25.92
Epoch: 120	Train Loss:  0.62	Test SSE:   26.92
Epoch: 140	Train Loss:  0.60	Test SSE:   27.12
Epoch: 160	Train Loss:  0.58	Test SSE:   26.80
Epoch: 180	Train Loss:  0.57	Test SSE:   26.52
Epoch: 200	Train Loss:  0.57	Test SSE:   27.23

Training for korea-all dataset with features=[309, 42, 84, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.77	Test SSE:   27.34
Epoch: 40	Train Loss:  0.72	Test SSE:   26.33
Epoch: 60	Train Loss:  0.69	Test SSE:   26.20
Epoch: 80	Train Loss:  0.66	Test SSE:   26.19
Epoch: 100	Train Loss:  0.64	Test SSE:   27.76
Epoch: 120	Train Loss:  0.63	Test SSE:   26.52
Epoch: 140	Train Loss:  0.61	Test SSE:   25.65
Epoch: 160	Train Loss:  0.59	Test SSE:   25.97
Epoch: 180	Train Loss:  0.58	Test SSE:   26.12
Epoch: 200	Train Loss:  0.57	Test SSE:   26.22

Training for korea-all dataset with features=[309, 42, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.75	Test SSE:   26.35
Epoch: 40	Train Loss:  0.71	Test SSE:   27.85
Epoch: 60	Train Loss:  0.67	Test SSE:   26.15
Epoch: 80	Train Loss:  0.65	Test SSE:   27.61
Epoch: 100	Train Loss:  0.63	Test SSE:   26.23
Epoch: 120	Train Loss:  0.61	Test SSE:   25.38
Epoch: 140	Train Loss:  0.59	Test SSE:   26.30
Epoch: 160	Train Loss:  0.58	Test SSE:   27.81
Epoch: 180	Train Loss:  0.57	Test SSE:   27.79
Epoch: 200	Train Loss:  0.56	Test SSE:   27.47

Training for korea-all dataset with features=[309, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.75	Test SSE:   26.82
Epoch: 40	Train Loss:  0.71	Test SSE:   25.93
Epoch: 60	Train Loss:  0.67	Test SSE:   25.91
Epoch: 80	Train Loss:  0.66	Test SSE:   26.96
Epoch: 100	Train Loss:  0.64	Test SSE:   26.73
Epoch: 120	Train Loss:  0.63	Test SSE:   26.41
Epoch: 140	Train Loss:  0.62	Test SSE:   26.61
Epoch: 160	Train Loss:  0.62	Test SSE:   27.17
Epoch: 180	Train Loss:  0.61	Test SSE:   27.06
Epoch: 200	Train Loss:  0.61	Test SSE:   27.06

SSE on testing dataset for korea-all with 10 layers:	27.8010
SSE on testing dataset for korea-all with 8 layers:	27.2287
SSE on testing dataset for korea-all with 6 layers:	26.2202
SSE on testing dataset for korea-all with 4 layers:	27.4692
SSE on testing dataset for korea-all with 2 layers:	27.0575
                                  
================================= 
Global information about the job: 
================================= 
  
Job owner: brywi(43322)
Job name:  bryan
Node list: ravg1038
Job start: Mon Oct 28 05:59:48 CET 2024
Job end:   Mon Oct 28 06:34:04 CET 2024
Work dir:  /raven/u/brywi/korea-happiness-ext
Command:   /raven/u/brywi/korea-happiness-ext/train.sh
  
  
  
==========================================================================================
Information on jobsteps (Note: MaxRSS/AveRSS is the maximum/average over all 
tasks of the per-task memory high-water marks; cf. "man sacct"): 
==========================================================================================
  
JobID            JobName NNodes NTasks  NCPUS       MaxRSS       AveRSS    Elapsed ExitCode
------------- ---------- ------ ------ ------ ------------ ------------ ---------- --------
13487907           bryan      1            36                             00:34:16      0:0
  
Maximum memory per node: 6.364192 GB (defined as MaxRSS*Ntasks/NNodes)
CPU utilization: 5.5 %
  

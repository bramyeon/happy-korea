Device: cuda
Data directory: ./data
Seed: 20244078
Data name: korea-medium
./data/corr-korea-simple.png
./data/corr-korea-basic.png
./data/preprocessed/korea-complex-test.csv
./data/preprocessed/korea-basic-test.csv
./data/preprocessed/korea-all.csv
./data/preprocessed/korea-simple-train.csv
./data/preprocessed/korea-medium-train.csv
./data/preprocessed/korea-basic-train.csv
./data/preprocessed/.DS_Store
./data/preprocessed/korea-complex-train.csv
./data/preprocessed/korea-all-test.csv
./data/preprocessed/korea-complex.csv
./data/preprocessed/korea-simple.csv
./data/preprocessed/korea-basic.csv
./data/preprocessed/korea-simple-test.csv
./data/preprocessed/korea-all-train.csv
./data/preprocessed/korea-medium.csv
./data/preprocessed/korea-medium-test.csv
Number of columns with NaN: 0
Correlation matrix save path: ./data/corr-korea-medium.png

A1                  0.614000
A2_1                0.539537
A2_2                0.520460
A2_3                0.480385
A3_1                0.537739
                      ...   
grdpno              0.014356
jobopen             0.012599
land                0.021315
trainee             0.022463
happiness_ladder    1.000000
Name: happiness_ladder, Length: 86, dtype: float64

==========

Batch size: 32
Number of input features: 86
Lucky number: 42
Epochs: 200
Adam betas: 0.9, 0.999
Criterion: MSE loss


Training for korea-medium dataset with features=[86, 42, 84, 168, 336, 672, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.82	Test SSE:   29.32
Epoch: 40	Train Loss:  0.77	Test SSE:   27.32
Epoch: 60	Train Loss:  0.74	Test SSE:   30.41
Epoch: 80	Train Loss:  0.72	Test SSE:   28.32
Epoch: 100	Train Loss:  0.69	Test SSE:   27.01
Epoch: 120	Train Loss:  0.66	Test SSE:   27.66
Epoch: 140	Train Loss:  0.64	Test SSE:   27.59
Epoch: 160	Train Loss:  0.62	Test SSE:   27.32
Epoch: 180	Train Loss:  0.59	Test SSE:   27.74
Epoch: 200	Train Loss:  0.57	Test SSE:   27.78

Training for korea-medium dataset with features=[86, 42, 84, 168, 336, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.82	Test SSE:   29.42
Epoch: 40	Train Loss:  0.77	Test SSE:   28.84
Epoch: 60	Train Loss:  0.75	Test SSE:   26.92
Epoch: 80	Train Loss:  0.72	Test SSE:   26.84
Epoch: 100	Train Loss:  0.70	Test SSE:   26.71
Epoch: 120	Train Loss:  0.67	Test SSE:   26.44
Epoch: 140	Train Loss:  0.65	Test SSE:   26.53
Epoch: 160	Train Loss:  0.64	Test SSE:   27.15
Epoch: 180	Train Loss:  0.62	Test SSE:   28.68
Epoch: 200	Train Loss:  0.61	Test SSE:   26.59

Training for korea-medium dataset with features=[86, 42, 84, 168, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.82	Test SSE:   30.72
Epoch: 40	Train Loss:  0.77	Test SSE:   27.33
Epoch: 60	Train Loss:  0.73	Test SSE:   26.98
Epoch: 80	Train Loss:  0.72	Test SSE:   26.36
Epoch: 100	Train Loss:  0.70	Test SSE:   26.36
Epoch: 120	Train Loss:  0.68	Test SSE:   28.02
Epoch: 140	Train Loss:  0.67	Test SSE:   26.56
Epoch: 160	Train Loss:  0.66	Test SSE:   26.58
Epoch: 180	Train Loss:  0.64	Test SSE:   26.01
Epoch: 200	Train Loss:  0.63	Test SSE:   26.21

Training for korea-medium dataset with features=[86, 42, 84, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.81	Test SSE:   28.51
Epoch: 40	Train Loss:  0.78	Test SSE:   28.45
Epoch: 60	Train Loss:  0.75	Test SSE:   27.82
Epoch: 80	Train Loss:  0.72	Test SSE:   26.84
Epoch: 100	Train Loss:  0.71	Test SSE:   27.16
Epoch: 120	Train Loss:  0.69	Test SSE:   27.47
Epoch: 140	Train Loss:  0.68	Test SSE:   27.14
Epoch: 160	Train Loss:  0.67	Test SSE:   26.82
Epoch: 180	Train Loss:  0.66	Test SSE:   27.11
Epoch: 200	Train Loss:  0.65	Test SSE:   26.81

Training for korea-medium dataset with features=[86, 42], lr=0.001, beta1=0.9, beta2=0.999, epochs=200
Epoch: 20	Train Loss:  0.81	Test SSE:   28.43
Epoch: 40	Train Loss:  0.77	Test SSE:   27.56
Epoch: 60	Train Loss:  0.75	Test SSE:   26.80
Epoch: 80	Train Loss:  0.74	Test SSE:   26.53
Epoch: 100	Train Loss:  0.73	Test SSE:   26.90
Epoch: 120	Train Loss:  0.73	Test SSE:   27.13
Epoch: 140	Train Loss:  0.72	Test SSE:   26.59
Epoch: 160	Train Loss:  0.72	Test SSE:   26.78
Epoch: 180	Train Loss:  0.71	Test SSE:   27.65
Epoch: 200	Train Loss:  0.71	Test SSE:   26.58

SSE on testing dataset for korea-medium with 10 layers:	27.7849
SSE on testing dataset for korea-medium with 8 layers:	26.5876
SSE on testing dataset for korea-medium with 6 layers:	26.2108
SSE on testing dataset for korea-medium with 4 layers:	26.8055
SSE on testing dataset for korea-medium with 2 layers:	26.5779
                                  
================================= 
Global information about the job: 
================================= 
  
Job owner: brywi(43322)
Job name:  bryan
Node list: ravg1177
Job start: Mon Oct 28 05:59:48 CET 2024
Job end:   Mon Oct 28 06:34:36 CET 2024
Work dir:  /raven/u/brywi/korea-happiness-ext
Command:   /raven/u/brywi/korea-happiness-ext/train.sh
  
  
  
==========================================================================================
Information on jobsteps (Note: MaxRSS/AveRSS is the maximum/average over all 
tasks of the per-task memory high-water marks; cf. "man sacct"): 
==========================================================================================
  
JobID            JobName NNodes NTasks  NCPUS       MaxRSS       AveRSS    Elapsed ExitCode
------------- ---------- ------ ------ ------ ------------ ------------ ---------- --------
13487901           bryan      1            36                             00:34:48      0:0
  
Maximum memory per node: 5.230567 GB (defined as MaxRSS*Ntasks/NNodes)
CPU utilization: 5.4 %
  
